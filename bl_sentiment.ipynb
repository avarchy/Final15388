{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment import util\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDVEC_PATH = r'C:\\Users\\Barry Li\\Documents\\nlp\\project\\vec\\glove.6B.100d.w2v.txt'\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(WORDVEC_PATH, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Wow. This is definitely not the usual North Korea bluffing. Consider me cautiously optimistic.'\n",
    "\n",
    "def neg_tokenize(text):\n",
    "    tokens = util.mark_negation(nltk.word_tokenize(text))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('confident', 0.7792400121688843),\n",
       " ('optimistic', 0.7275913953781128),\n",
       " ('cautious', 0.7191028594970703),\n",
       " ('hope', 0.7072612047195435),\n",
       " ('satisfied', 0.6978720426559448),\n",
       " ('feeling', 0.6955770254135132),\n",
       " ('good', 0.6901206970214844),\n",
       " ('feel', 0.6896106004714966),\n",
       " ('pleased', 0.6865102648735046),\n",
       " ('happy', 0.6839694976806641)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_keywords = ['hopeful', 'sincere', 'calm', 'attitude']\n",
    "model.most_similar(positive=positive_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wary', 0.76902174949646),\n",
       " ('anxious', 0.7585034370422363),\n",
       " ('hesitant', 0.7413669228553772),\n",
       " ('timid', 0.7065054774284363),\n",
       " ('impatient', 0.7036861181259155),\n",
       " ('ambivalent', 0.6842986941337585),\n",
       " ('skeptical', 0.6806875467300415),\n",
       " ('apprehensive', 0.679796576499939),\n",
       " ('skittish', 0.6772457957267761),\n",
       " ('pessimistic', 0.6748073101043701)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_keywords = ['scared', 'anxious', 'cautious', 'stressful', 'alert', 'emotion', 'attitude']\n",
    "negative_keywords = ['cautious', 'untrusting', 'fearful', 'attitude']\n",
    "model.most_similar(positive=negative_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos 161\n",
      "neg 159\n"
     ]
    }
   ],
   "source": [
    "pos_200 = model.most_similar(positive=positive_keywords, topn=200)\n",
    "neg_200 = model.most_similar(positive=negative_keywords, topn=200)\n",
    "\n",
    "uni_features = {}\n",
    "for word, sim in pos_200:\n",
    "    score = uni_features.get(word, 0)\n",
    "    uni_features[word] = score + sim\n",
    "for word, sim in neg_200:\n",
    "    score = uni_features.get(word, 0)\n",
    "    if score > sim:\n",
    "        uni_features[word] = score\n",
    "    else:\n",
    "        uni_features[word] = -1 * sim\n",
    "\n",
    "for stopword in ENGLISH_STOP_WORDS:\n",
    "    uni_features.pop(stopword, None)\n",
    "print('pos', len([v for k, v in uni_features.items() if v > 0]))\n",
    "print('neg', len([v for k, v in uni_features.items() if v < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79297072  1.82907706  2.68077487 -1.13360691  0.59415591 -0.01073837\n",
      "  0.         -0.00861579]\n"
     ]
    }
   ],
   "source": [
    "class SentAnalyzer():\n",
    "    \n",
    "    def __init__(self, features):\n",
    "        neg_features = self.duplicate_negation(features)\n",
    "        neg_features.update(features)\n",
    "        self.features = neg_features\n",
    "        idxs = {feat: i for i, feat in enumerate(self.features)}\n",
    "        self.idxs = idxs\n",
    "        self.vectorizer = CountVectorizer(vocabulary=idxs, tokenizer=neg_tokenize)\n",
    "        flipped_idxs = {i: self.features[feat] for feat, i in idxs.items()}\n",
    "        self.weights = np.array([flipped_idxs[i] for i in range(len(flipped_idxs))])\n",
    "    \n",
    "    def duplicate_negation(self, features):\n",
    "        neg_features = {\n",
    "            '{}_NEG'.format(feat): -1 * score for feat, score in features.items()\n",
    "        }\n",
    "        return neg_features\n",
    "    \n",
    "    def normalize(self, score, alpha=15):\n",
    "        \"\"\"Normalizing function as described by VADER Sentiment analyzer\"\"\"\n",
    "        return score / np.sqrt((score * score) + alpha)\n",
    "    \n",
    "    def polarize(self, passages):\n",
    "        \"\"\"Calculate the polarity of a passage.\n",
    "        \n",
    "        passage [str]: a list of strings representing tokens\n",
    "        \"\"\"\n",
    "        bow_vec = self.vectorizer.transform(passages)\n",
    "        return bow_vec.dot(self.weights)\n",
    "    \n",
    "    def predict(self, passage):\n",
    "        return self.polarize(passage)\n",
    "    \n",
    "SA = SentAnalyzer(uni_features)\n",
    "test2 = \"I'm still really skeptical myself. This is all just too good to be true. \\nWhat the fuck is Kim actually planning? How the fuck is North Korea going to unify with South Korea when NK has the most fucked up and brainwashed population in existence?\"\n",
    "test3 = \"I'm really optimistic. I hope this succeeds.\"\n",
    "test4 = \"Is it really happening? There is no obvious reason to believe him and this is all happening so fast? Could something amazing actually be happening here?\"\n",
    "test5 = \"Got the warning on my phone. I was just talking to friends on discord then heard the weird note from my phone that I hear for the first time. I checked it says missile. I was terrified checking every news source and calling friends. Then got another saying it passed over. That was terrifying.\"\n",
    "test6 = \"I've been living in northern Japan for some time and have never seen this kind of response to a missile launch before. The alerts, the news broadcasts, it was not taken lightly. Regardless of where the missile ended up, I think the message it sent is one that will have some lasting implications on how we perceive North Korea's aggression. It's only a matter of time before they end their war with Poseidon and make the mistake of targeting actual human lives. Stay safe out there, everyone.\"\n",
    "test7 = \"Their targeting systems and missiles are far from foolproof. A missile failure could have dropped this missile on an inhabited area in Japan. That would likely have provoked a full scale war. The level of irresponsibility here is just staggering.\"\n",
    "test8 = \"Man, that must be scary as shit. The other day I just arrived in Brussels and sat down in the Grand Place (a big open square, right in the center of Brussels) and then got a BBC alert 'Machete-wielding man attacks soldiers in central Brussels'. My heart skipped a beat. It was just a couple of streets away. I felt kinda sick. I did hear police sirens earlier but didn't think much of it. There were also soldiers and police all over the place.\"\n",
    "print(SA.predict([test, test2, test3, test4, test5, test6, test7, test8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
